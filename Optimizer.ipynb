{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJ0zRYgoOSLz9irRax9imo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a5c59089e3954cebb043459caca01cb1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3f2a1cc02e7a4e3e8355a8e55375c446",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "üñ•Ô∏è GPU Status:\n",
                  "‚îú‚îÄ Utilization: 0.0%\n",
                  "‚îú‚îÄ Memory Used: 105.0/15360.0 MB\n",
                  "‚îî‚îÄ Memory Utilization: 0.7%\n",
                  "\n",
                  "üìã Running Tasks:\n",
                  "‚îî‚îÄ No tasks currently running\n",
                  "\n",
                  "üìä Queue Status:\n",
                  "‚îî‚îÄ No tasks in queue\n"
                ]
              }
            ]
          }
        },
        "3f2a1cc02e7a4e3e8355a8e55375c446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a460b7646f94e01b790e32850980798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fc199010579477ca22c11e78d09f982",
              "IPY_MODEL_68655dd6d33546ac9a6e4e23828d487c",
              "IPY_MODEL_f83e74e49aa24126aed7d85641af6878"
            ],
            "layout": "IPY_MODEL_52a2cbe48b334ee5ac6e28afa01756bd"
          }
        },
        "9fc199010579477ca22c11e78d09f982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b90d4a4743247149e84d662bd11077f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4d96410f27154d95b941c37f86233925",
            "value": "Adding‚Äátasks:‚Äá100%"
          }
        },
        "68655dd6d33546ac9a6e4e23828d487c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c65ba19d364686accac07ed63f0bb7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_640ed7f4ab9f40279bdf984f91b08112",
            "value": 3
          }
        },
        "f83e74e49aa24126aed7d85641af6878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf724e7d7c0648ee8c0d5149f81f5f23",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a870c9c0a77543b5b48277e85971e155",
            "value": "‚Äá3/3‚Äá[00:03&lt;00:00,‚Äá‚Äá1.01s/it]"
          }
        },
        "52a2cbe48b334ee5ac6e28afa01756bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b90d4a4743247149e84d662bd11077f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d96410f27154d95b941c37f86233925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52c65ba19d364686accac07ed63f0bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640ed7f4ab9f40279bdf984f91b08112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf724e7d7c0648ee8c0d5149f81f5f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a870c9c0a77543b5b48277e85971e155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InannaxX07/Optimizer/blob/main/Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a5c59089e3954cebb043459caca01cb1",
            "3f2a1cc02e7a4e3e8355a8e55375c446",
            "6a460b7646f94e01b790e32850980798",
            "9fc199010579477ca22c11e78d09f982",
            "68655dd6d33546ac9a6e4e23828d487c",
            "f83e74e49aa24126aed7d85641af6878",
            "52a2cbe48b334ee5ac6e28afa01756bd",
            "6b90d4a4743247149e84d662bd11077f",
            "4d96410f27154d95b941c37f86233925",
            "52c65ba19d364686accac07ed63f0bb7",
            "640ed7f4ab9f40279bdf984f91b08112",
            "bf724e7d7c0648ee8c0d5149f81f5f23",
            "a870c9c0a77543b5b48277e85971e155"
          ]
        },
        "id": "CVz-Y2w2Mydk",
        "outputId": "b8e3ccb0-f9c4-4f75-882b-e5603ad6c2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in monitoring loop: 'GPUTaskScheduler' object has no attribute '_process_completed_tasks'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in monitoring loop: 'GPUTaskScheduler' object has no attribute '_process_completed_tasks'\n",
            "ERROR:__main__:Error in monitoring loop: 'GPUTaskScheduler' object has no attribute '_process_completed_tasks'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan  6 20:29:31 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0              32W /  70W |    105MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5c59089e3954cebb043459caca01cb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in monitoring loop: 'GPUTaskScheduler' object has no attribute '_process_completed_tasks'\n",
            "ERROR:__main__:Error in monitoring loop: 'GPUTaskScheduler' object has no attribute '_process_completed_tasks'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "To add more tasks, use:\n",
            "\n",
            "    new_task = {\n",
            "        'id': 4,  # Use a new unique ID\n",
            "        'task_type': 'training',\n",
            "        'model_size': 'small',\n",
            "        'priority': 4,\n",
            "        'expected_duration': 60,\n",
            "        'batch_size': 16\n",
            "    }\n",
            "    scheduler.add_task(new_task)\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# First, install required packages\n",
        "!pip install torch psutil numpy scikit-learn tqdm ipywidgets\n",
        "\n",
        "import torch\n",
        "import psutil\n",
        "import time\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import threading\n",
        "from typing import List, Dict, Optional\n",
        "import logging\n",
        "from dataclasses import dataclass\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import concurrent.futures\n",
        "from IPython.display import clear_output, display\n",
        "from tqdm.notebook import tqdm\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Configure logging for Colab\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class TaskMetrics:\n",
        "    memory_usage: float\n",
        "    gpu_utilization: float\n",
        "    duration: float\n",
        "    task_type: str\n",
        "    model_size: str\n",
        "    batch_size: Optional[int] = None\n",
        "\n",
        "class ResourcePredictor:\n",
        "    \"\"\"Predicts resource usage for tasks\"\"\"\n",
        "    def __init__(self):\n",
        "        self.model = RandomForestRegressor()\n",
        "        self.training_data = []\n",
        "\n",
        "    def update(self, metrics: TaskMetrics):\n",
        "        \"\"\"Update predictor with new task metrics\"\"\"\n",
        "        self.training_data.append({\n",
        "            'memory_usage': metrics.memory_usage,\n",
        "            'gpu_utilization': metrics.gpu_utilization,\n",
        "            'duration': metrics.duration,\n",
        "            'task_type': metrics.task_type,\n",
        "            'model_size': metrics.model_size,\n",
        "            'batch_size': metrics.batch_size or 0\n",
        "        })\n",
        "\n",
        "class ColabGPUMonitor:\n",
        "    \"\"\"GPU monitoring specifically for Colab environment\"\"\"\n",
        "    def __init__(self):\n",
        "        self.output = widgets.Output()\n",
        "\n",
        "    def get_gpu_info(self):\n",
        "        \"\"\"Get GPU info using nvidia-smi\"\"\"\n",
        "        try:\n",
        "            gpu_info = !nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits\n",
        "            gpu_info = gpu_info[0].split(',')\n",
        "            return {\n",
        "                'gpu_util': float(gpu_info[0]),\n",
        "                'memory_used': float(gpu_info[1]),\n",
        "                'memory_total': float(gpu_info[2])\n",
        "            }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting GPU info: {str(e)}\")\n",
        "            return {\n",
        "                'gpu_util': 0,\n",
        "                'memory_used': 0,\n",
        "                'memory_total': 1\n",
        "            }\n",
        "\n",
        "    def display_status(self, scheduler):\n",
        "        \"\"\"Display current GPU and task status\"\"\"\n",
        "        with self.output:\n",
        "            clear_output(wait=True)\n",
        "            gpu_info = self.get_gpu_info()\n",
        "\n",
        "            print(\"üñ•Ô∏è GPU Status:\")\n",
        "            print(f\"‚îú‚îÄ Utilization: {gpu_info['gpu_util']}%\")\n",
        "            print(f\"‚îú‚îÄ Memory Used: {gpu_info['memory_used']}/{gpu_info['memory_total']} MB\")\n",
        "            print(f\"‚îî‚îÄ Memory Utilization: {(gpu_info['memory_used']/gpu_info['memory_total'])*100:.1f}%\\n\")\n",
        "\n",
        "            print(\"üìã Running Tasks:\")\n",
        "            if scheduler.running_tasks:\n",
        "                for task_id, task in scheduler.running_tasks.items():\n",
        "                    if task.get('start_time'):\n",
        "                        elapsed = time.time() - task['start_time']\n",
        "                        progress = min(100, (elapsed / task['expected_duration']) * 100)\n",
        "                        print(f\"‚îú‚îÄ Task {task_id} ({task['task_type']}, Priority {task['priority']})\")\n",
        "                        print(f\"‚îÇ  ‚îî‚îÄ Progress: {progress:.1f}% complete\")\n",
        "            else:\n",
        "                print(\"‚îî‚îÄ No tasks currently running\")\n",
        "\n",
        "            print(\"\\nüìä Queue Status:\")\n",
        "            total_queued = sum(len(q) for q in scheduler.priority_queues.values())\n",
        "            if total_queued > 0:\n",
        "                for priority, queue in scheduler.priority_queues.items():\n",
        "                    if len(queue) > 0:\n",
        "                        print(f\"‚îú‚îÄ Priority {priority}: {len(queue)} tasks waiting\")\n",
        "            else:\n",
        "                print(\"‚îî‚îÄ No tasks in queue\")\n",
        "\n",
        "class GPUTaskScheduler:\n",
        "    \"\"\"GPU Task Scheduler optimized for Google Colab\"\"\"\n",
        "\n",
        "    def __init__(self, memory_threshold: float = 0.85, utilization_threshold: float = 0.80):\n",
        "        self.memory_threshold = memory_threshold\n",
        "        self.utilization_threshold = utilization_threshold\n",
        "        self.tasks = []\n",
        "        self.running_tasks = {}\n",
        "        self.resource_predictor = ResourcePredictor()\n",
        "        self.lock = threading.Lock()\n",
        "        self.priority_queues = {i: deque() for i in range(1, 6)}\n",
        "        self.stop_event = threading.Event()\n",
        "        self.monitor = ColabGPUMonitor()\n",
        "\n",
        "        # Check Colab GPU availability\n",
        "        try:\n",
        "            !nvidia-smi\n",
        "            if not torch.cuda.is_available():\n",
        "                raise RuntimeError(\"No GPU available. Please enable GPU in Colab.\")\n",
        "            self.num_gpus = torch.cuda.device_count()\n",
        "            logger.info(f\"Initialized scheduler with {self.num_gpus} GPU(s)\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error initializing GPU: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "        # Display the monitoring widget\n",
        "        display(self.monitor.output)\n",
        "\n",
        "    def _process_completed_tasks(self):\n",
        "        \"\"\"Process and remove completed tasks from running tasks.\"\"\"\n",
        "        try:\n",
        "            current_time = time.time()\n",
        "            completed_tasks = []\n",
        "\n",
        "            for task_id, task in list(self.running_tasks.items()):\n",
        "                if task.get('start_time') is None:\n",
        "                    continue\n",
        "\n",
        "                elapsed_time = current_time - task['start_time']\n",
        "\n",
        "                if elapsed_time >= task['expected_duration'] * 1.1:\n",
        "                    task['completion_time'] = current_time\n",
        "                    task['status'] = 'completed'\n",
        "                    completed_tasks.append(task_id)\n",
        "\n",
        "                    logger.info(f\"Task {task_id} completed. Duration: {elapsed_time:.2f}s\")\n",
        "\n",
        "                    try:\n",
        "                        metrics = TaskMetrics(\n",
        "                            memory_usage=self.monitor.get_gpu_info()['memory_used'],\n",
        "                            gpu_utilization=self.monitor.get_gpu_info()['gpu_util'],\n",
        "                            duration=elapsed_time,\n",
        "                            task_type=task['task_type'],\n",
        "                            model_size=task['model_size'],\n",
        "                            batch_size=task.get('batch_size')\n",
        "                        )\n",
        "                        self.resource_predictor.update(metrics)\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error collecting metrics for task {task_id}: {str(e)}\")\n",
        "\n",
        "            for task_id in completed_tasks:\n",
        "                self.running_tasks.pop(task_id, None)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing completed tasks: {str(e)}\")\n",
        "\n",
        "    def _can_schedule_task(self, task):\n",
        "        \"\"\"Check if there are sufficient resources to schedule a task.\"\"\"\n",
        "        try:\n",
        "            gpu_info = self.monitor.get_gpu_info()\n",
        "\n",
        "            memory_usage = gpu_info['memory_used'] / gpu_info['memory_total']\n",
        "            if memory_usage > self.memory_threshold:\n",
        "                return False\n",
        "\n",
        "            if gpu_info['gpu_util'] > self.utilization_threshold * 100:\n",
        "                return False\n",
        "\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error checking resource availability: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _schedule_queued_tasks(self):\n",
        "        \"\"\"Schedule queued tasks based on priority and resource availability.\"\"\"\n",
        "        try:\n",
        "            for priority in range(5, 0, -1):\n",
        "                queue = self.priority_queues[priority]\n",
        "\n",
        "                while queue and self._can_schedule_task(queue[0]):\n",
        "                    task = queue.popleft()\n",
        "                    task['start_time'] = time.time()\n",
        "                    task['status'] = 'running'\n",
        "\n",
        "                    self.running_tasks[task['id']] = task\n",
        "                    logger.info(f\"Started task {task['id']} (Priority {priority})\")\n",
        "\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error scheduling tasks: {str(e)}\")\n",
        "\n",
        "    def add_task(self, task: dict) -> bool:\n",
        "        \"\"\"Add a new task to the scheduler's priority queue.\"\"\"\n",
        "        try:\n",
        "            if 'priority' not in task or not 1 <= task['priority'] <= 5:\n",
        "                logger.error(f\"Invalid priority for task {task.get('id')}\")\n",
        "                return False\n",
        "\n",
        "            required_fields = ['id', 'task_type', 'model_size', 'expected_duration']\n",
        "            if not all(field in task for field in required_fields):\n",
        "                logger.error(f\"Missing required fields for task {task.get('id')}\")\n",
        "                return False\n",
        "\n",
        "            task_entry = {\n",
        "                **task,\n",
        "                'status': 'queued',\n",
        "                'submit_time': time.time(),\n",
        "                'start_time': None,\n",
        "                'completion_time': None\n",
        "            }\n",
        "\n",
        "            with self.lock:\n",
        "                self.priority_queues[task['priority']].append(task_entry)\n",
        "                logger.info(f\"Added task {task['id']} to priority queue {task['priority']}\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error adding task {task.get('id')}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def monitor_and_optimize(self, interval: float = 1.0):\n",
        "        \"\"\"Monitor GPU usage with Colab-specific display\"\"\"\n",
        "        while not self.stop_event.is_set():\n",
        "            try:\n",
        "                with self.lock:\n",
        "                    self._process_completed_tasks()\n",
        "                    self._schedule_queued_tasks()\n",
        "\n",
        "                self.monitor.display_status(self)\n",
        "                time.sleep(interval)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in monitoring loop: {str(e)}\")\n",
        "                time.sleep(interval)\n",
        "\n",
        "    def get_task_status(self, task_id: int) -> dict:\n",
        "        \"\"\"Get the current status of a specific task.\"\"\"\n",
        "        try:\n",
        "            if task_id in self.running_tasks:\n",
        "                task = self.running_tasks[task_id]\n",
        "                if task.get('start_time'):\n",
        "                    elapsed = time.time() - task['start_time']\n",
        "                    progress = min(100, (elapsed / task['expected_duration']) * 100)\n",
        "                    return {\n",
        "                        'status': 'running',\n",
        "                        'progress': progress,\n",
        "                        'elapsed_time': elapsed\n",
        "                    }\n",
        "\n",
        "            for priority, queue in self.priority_queues.items():\n",
        "                for task in queue:\n",
        "                    if task['id'] == task_id:\n",
        "                        return {\n",
        "                            'status': 'queued',\n",
        "                            'priority': priority,\n",
        "                            'queue_position': list(queue).index(task)\n",
        "                        }\n",
        "\n",
        "            return {'status': 'not_found'}\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting task status: {str(e)}\")\n",
        "            return {'status': 'error', 'message': str(e)}\n",
        "\n",
        "    def cancel_task(self, task_id: int) -> bool:\n",
        "        \"\"\"Cancel a running or queued task.\"\"\"\n",
        "        try:\n",
        "            if task_id in self.running_tasks:\n",
        "                task = self.running_tasks.pop(task_id)\n",
        "                task['status'] = 'cancelled'\n",
        "                logger.info(f\"Cancelled running task {task_id}\")\n",
        "                return True\n",
        "\n",
        "            for priority, queue in self.priority_queues.items():\n",
        "                for task in queue:\n",
        "                    if task['id'] == task_id:\n",
        "                        queue.remove(task)\n",
        "                        logger.info(f\"Cancelled queued task {task_id}\")\n",
        "                        return True\n",
        "\n",
        "            logger.warning(f\"Task {task_id} not found for cancellation\")\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error cancelling task {task_id}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "# Run example\n",
        "def run_example():\n",
        "    \"\"\"Run an example workload in Colab\"\"\"\n",
        "    scheduler = GPUTaskScheduler()\n",
        "\n",
        "    monitor_thread = threading.Thread(\n",
        "        target=scheduler.monitor_and_optimize,\n",
        "        args=(1.0,),\n",
        "        daemon=True\n",
        "    )\n",
        "    monitor_thread.start()\n",
        "\n",
        "    example_tasks = [\n",
        "        {\n",
        "            'id': 1,\n",
        "            'task_type': 'training',\n",
        "            'model_size': 'large',\n",
        "            'priority': 5,\n",
        "            'expected_duration': 60,\n",
        "            'batch_size': 32\n",
        "        },\n",
        "        {\n",
        "            'id': 2,\n",
        "            'task_type': 'inference',\n",
        "            'model_size': 'small',\n",
        "            'priority': 3,\n",
        "            'expected_duration': 30,\n",
        "            'batch_size': 16\n",
        "        },\n",
        "        {\n",
        "            'id': 3,\n",
        "            'task_type': 'training',\n",
        "            'model_size': 'medium',\n",
        "            'priority': 4,\n",
        "            'expected_duration': 45,\n",
        "            'batch_size': 24\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for task in tqdm(example_tasks, desc=\"Adding tasks\"):\n",
        "        scheduler.add_task(task)\n",
        "        time.sleep(1)\n",
        "\n",
        "    return scheduler\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    scheduler = run_example()\n",
        "\n",
        "    print(\"\\nTo add more tasks, use:\")\n",
        "    print(\"\"\"\n",
        "    new_task = {\n",
        "        'id': 4,  # Use a new unique ID\n",
        "        'task_type': 'training',\n",
        "        'model_size': 'small',\n",
        "        'priority': 4,\n",
        "        'expected_duration': 60,\n",
        "        'batch_size': 16\n",
        "    }\n",
        "    scheduler.add_task(new_task)\n",
        "    \"\"\")"
      ]
    }
  ]
}